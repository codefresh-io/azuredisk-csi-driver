## changes to fix attach delay issues

Issue: https://github.com/kubernetes-sigs/azuredisk-csi-driver/issues/269

*Solution:*
- introducing locks on node+lun level in addition to locks on node level
- on ControllerPublishVolume we do not WaitForCompletion for AzureApi long ops to complete so Node object is populated with disk immediately
- node level lock releases after Update 
- call WaitForCompletion in background releasing node+lun locks and refreshing node cache on it completion
- on NodeStageVolume we wait until scsi device is attached to the node, so kubelet will not spin on exponensial backoff

##### controller code changes 
1. Move k8s.io/legacy-cloud-providers/azure into this repo (sigs.k8s.io/azuredisk-csi-driver/pkg/azure) and change imports
2. Introducing locks on Node+Lun level - changing azure_controller_common.go to call AcquireNextDiskLun instead of GetNextDiskLun and adding code to lockMap azure_utils.go 
3. separate WaitForCompletion from Update call AzureVMSS in pkg/azure/azure_client.go - func (az *azVirtualMachineScaleSetVMsClient) UpdateFuture and FutureWaitForCompletion
4. in pkg/azure/azure_controller_vmss.go on both attach/detach we call FutureWaitForCompletion in goroutine to be continue executing after Conptroller(Un)PublishVolume exits. 
5. non-vmss instances - to be done

##### node code changes
1. on findDiskAndLun (pkg/nodeserver.go) we wait with 2m timeout until device is added to the node so kubelet will wait intead of retry with exp. backoff

